


```{r}
library(rjags)
library(coda)
library(ggplot2)
library(dplyr)
```

## A normal null model

This model is a normal-distribution based random walk model that guesses that the next step of a system is just the previous step plus year-year variability. 

## Developing priors

# A Prior on the rate of underreporting

We use the Nelson et al 2015 study that estimated underreporting nationally by about 10-fold using insurance claims. They reported that the CDC numbers (9.4 per 100000) were actually 106.6 per 100000 minus 10% or plus 11.42%. That was based on 2005-2010 data, which includes data from before the CDC chagned thier reporting criteria. 

There are several compounding factors: This is a national estimate of observational error, representing two different CDC reporting strategies, and covering a time period that has little overlap with our model fits. To account for this error, we will say the mean error is a 10-fold increase, but that the varibilty around that error is large- anywhere from a sligth underestimate to a 22-fold increase. This roughly agrees with other liturature mentioned in the paper (the Hinckley et al paper, which focuses on false negatives from serology tests and the many case-studies in the Mead 2015 paper). 

```{r}
## Priors to be put into a gamma distrbution for rate of underreporting 
 s_under = 10 / (2) # prior for underreporting plus and order of magnitude
 a_under = s_under * 10 # Moment matching 

```

# A prior on yearly variability 
We generated a prior for yearly variability by taking the differences in year-year from non-cumberland counties. We then moment matched that distribution. If we plan on extending this analysis to  the rest of maine, will have to make a prior from non-maine states. 

```{r}
## Find year to year variation for each town
towns_in_rest_of_maine <- unique(tick_disease_big$Location)
variations <- c()
for (i in seq_along(towns_in_rest_of_maine)){
  
  town_name <- towns_in_rest_of_maine[i]
  tick_data <- tick_disease_big

  tick_disease_tmp <- tick_data[(tick_data$Location == town_name ),] 
  tick_disease_tmp <- dplyr::filter(tick_disease_tmp, tick_disease_tmp$Year >= 2008)
  tick_disease_tmp <- dplyr::filter(tick_disease_tmp, tick_disease_tmp$Year < 2016) 
  
  print(town_name)
  for(j in 1:(length(tick_disease_tmp$Year-1))){
    
    is_numeric_j <- try(as.numeric(tick_disease_tmp$Number[j]))
    is_numeric_j_next <- try(as.numeric(tick_disease_tmp$Number[j + 1]))
    
    if(!is.na(is_numeric_j) && !is.na(is_numeric_j_next)){
      diff <- as.numeric(tick_disease_tmp$Number[j]) - as.numeric(tick_disease_tmp$Number[j + 1])
      #print(diff)
    }else{
      #print(".....Skipping.....")
      next  ## skip over all year-year variablility in suppressed data.  Imperfect. 
    }
    
    variations <- c(variations, diff)
  }
  
}

## Take mean of that distribution
hist(variations)
mean_year_year_variability <- mean(variations)  
year_to_year_variability <- var(variations)
s = mean_year_year_variability / (year_to_year_variability*10) # prior for year-year variability plus and order of magnitude
a = s * mean_year_year_variability # Moment matching 




```


# A prior on x_ic

This parameter represents the latent state of the system in 2008. I calculate the latent state of the model by sampling a random number from the invers of the data model. In this case, the data model is multiplied by the rate of underrepoting.  


```{r}
## Declare matrix to store x_ic values per town
town_x_ic <- matrix(nrow = length(towns_to_run), ncol = 2)
town_x_ic <- as.data.frame(town_x_ic)
names(town_x_ic) <- c("Location", "x_ic")


## Cycle through towns and do a random pull from data model
for (i in seq_along(towns_to_run)){
  town_name <- towns_to_run[i]
  tick_data <- tick_disease

  tick_disease_tmp <- tick_data[(tick_data$Location == town_name ),] 
  tick_disease_tmp <- dplyr::filter(tick_disease_tmp, tick_disease_tmp$Year == 2008)
  
  is_numeric <- try(as.numeric(tick_disease_tmp$Rate))
  
  if(!is.na(is_numeric)){
    obs_ticks <- is_numeric  # Correct for difference in sampling. 
  }else{
    obs_ticks <- 2.5
    
  } 
  town_x_ic$Location[i] <- town_name
  if(obs_ticks < 1){ obs_ticks <- 0.1} # Multiplying 0 by 0 will still be zero. Putting small number. 
  obs_ticks <- obs_ticks * rgamma(1, a, s)
  town_x_ic$x_ic[i] <- obs_ticks
 
}
 
town_x_ic$x_ic <- town_x_ic$x_ic 

```



## Jags model function

```{r}
fit_rate_random_walk <- function(tick_data, has_suppressed = TRUE, town_name, n.iter = 91000, data_list ){
  
  tick_data <- dplyr::arrange(tick_data, by = tick_data$Year) # Make sure to be going in order of year
   
  
  less_than_six_indices <- which(tick_data$Number == "<6" )
  numeric_indices <- which(tick_data$Number != "<6")
  
  data_list$n <- length(tick_data$Year) 
  data_list$numeric_indices <- numeric_indices
  data_list$less_than_six_indices <- less_than_six_indices

  
  ## Check if has suppressed data. If yes, provide flow control
  if (rlang::is_empty(less_than_six_indices)){
   has_suppressed <- FALSE
  }
  
  if(has_suppressed){
    RandomWalk = "
model{
  
  #### Data Model
  for(t in numeric_indices){
   y[t] ~ dnorm(x[t], 1/rate_of_underreporting) T(0,) 
   rate_cutoff_low[t] <- 0 # Filler value
   rate_cutoff_high[t] <- 9999 # Filler value
 }
 
  for(t in less_than_six_indices){   
   rate_cutoff_low[t] <- ((1/pop[t]) * 100000)
   rate_cutoff_high[t] <- ((5/pop[t]) * 100000)
   y[t] ~ dnorm(x[t], 1/rate_of_underreporting) T(rate_cutoff_low[t], rate_cutoff_high[t])
  }

  #### Process Model
   for (i in 2:n){
   z[i] ~ dnorm(x[i - 1],yearly_variability)
   x[i] <- max(0.000001, z[i])
  }

   ### Swap varience for precision
  yearly_variability <- 1/ (prior_on_yearly_variability)
  

  #### Priors
  #observation_error ~ dnorm(obs_mean, 1/obs_var)
  rate_of_underreporting ~ dgamma(a_under, s_under)
  ic_var <- obs_var  
  x[1] ~ dnorm(x_ic, 1/(ic_var))
  prior_on_yearly_variability ~ dgamma(a, s) # Fit from non cumberland data
}
"
  }else{
        RandomWalk = "
model{
  
  #### Data Model
  for(t in numeric_indices){
   y[t] ~ dnorm(q[t], 1/rate_of_underreporting) T(0,) 
 }

  #### Process Model
  for (i in 2:n){
   z[i] ~ dnorm(x[i - 1],yearly_variability)
   x[i] <- max(0.000001, z[i])
  }

  
  ### Swap varience for precision
  yearly_variability <- 1/(prior_on_yearly_variability)
  

  #### Priors
  #observation_error ~ dnorm(obs_mean, obs_var)
  rate_of_underreporting ~ dgamma(a_under, s_under)
  ic_var <- obs_var 
  x[1] ~ dnorm(x_ic, 1/(ic_var))
  prior_on_yearly_variability ~ dgamma(a, s) # Fit from non cumberland data
}
"
  }



## setting  initial conditions
nchain = 3
init <- list()
for(i in 1:nchain){
  init[[i]] <- list() 
}


j.model   <- jags.model (file = textConnection(RandomWalk),
                             data = data_list,
                             #inits = init,
                             n.chains = 3)

jags.out   <- coda.samples (model = j.model,
                            variable.names = c( "x", "yearly_variability", "rate_of_underreporting"),
                                n.iter = n.iter)

GBR <- gelman.plot(jags.out)
burnin <- GBR$last.iter[tail(which(apply(GBR$shrink[,,2]>1.05,1,any)),1)+1] ## Cut our burn-in. 

if(is.na(burnin)){
  warning("GBR !< 1.05. Model may have failed to converge")
  jags.burn <- jags.out
  did_it_converge <- "convergence_failed_GBR_test" 
  
}else{
  did_it_converge <- "convergence_passed_GBR_test"
  jags.burn <- window(jags.out,start=burnin, extend = FALSE)
}
  date_stamp <- Sys.time()
  date_stamp <- format(date_stamp, "%Y%m%d")
  file_name <- paste("/Users/tess/Documents/work/Maine_Tick_Disease_Forecast/Jags_output/", date_stamp, ".", "rate_random_walk",".",town_name,".", did_it_converge, ".","JAGS_run.Rdata", sep = "")
  print(did_it_converge)
  print(effectiveSize(jags.burn))
  save(jags.burn, file = file_name )
  return(jags.burn)
}
```


## Looping over every town in cumberland 

 
```{r}

for (i in seq_along(towns_to_run)){
  
 town_name <- towns_to_run[i]


  tick_disease_tmp <- tick_disease[(tick_disease$Location == town_name ),] 
  tick_disease_tmp <- dplyr::filter(tick_disease_tmp, tick_disease_tmp$Year > 2008) # Used 2008 as prior on system
  tick_disease_tmp$Number[tick_disease_tmp$Year > 2016] <- NA # Hold out three years for validation. 
  tick_disease_tmp <- dplyr::arrange(tick_disease_tmp, by = tick_disease_tmp$Year) %>%
                       dplyr::distinct()# Make sure model is fitting through time
  
data_list <- list( 
            s_under = s_under, 
            a_under = a_under, 
            obs_mean = obs_mean, 
            obs_var = obs_var, 
            n = 7, 
            a = a, 
            s = s , 
            y = tick_disease_tmp$Rate,  
            x_ic = town_x_ic$x_ic[town_x_ic$Location == town_name] , 
            pop = as.numeric(tick_disease_tmp$Population)
            )

print(town_name)
output <- fit_rate_random_walk(tick_disease_tmp, has_suppressed = TRUE, town_name, n.iter = 1000000, data_list )
  
}

```

# Lit review for error rates in lyme reporting

*National Estimates of Errors*

Some national error estimates include [this paper](https://academic.oup.com/cid/article/59/5/676/2895755) by Hinckley et al, which estimates the "true" number of infections in 2008 based on the number of specimines sent into labs, and correcting for false positives and false negatives. It does not estimate the number of incidences where the tick itself was not sent in for testing, but says this could add to the number. 

[This CDC summary](https://www.cdc.gov/mmwr/volumes/66/ss/ss6622a1.htm?s_cid=ss6622a1_w) of the 2008-2015 data notes that tick disease rates are underreported in high-incidence areas but possibly over-reported in low-incidence areas.
  Starting in 2008, the CDC explicitly notes the difference between confirmed cases and probable cases. This difference could be used to estimate some of the error, but is also likely an underestimate because the definition of "probable case" still involves some positive lab results/ medical diagnosis. 

[This estimate](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4550147/) of 2005-2010 national incidence rate useing health insurence claims also argues for large numbers of underreporting. 

[This review](https://www-sciencedirect-com.ezproxy.bu.edu/science/article/pii/S0891552015000240?via%3Dihub) as well as being a thourough general review of lyme in the united states, summerizes some of the liturature attemting to estimate the amount of underreporting in lyme disease, putting it aproximatly 3-12 fold differences. The studies were state/ town specific but the techniqes used were: 
 - In Westchestesr New York a "determinisitc model with plausible ranges" [was used](https://academic.oup.com/aje/article/148/10/1018/135572) to estimate "true" incidence levels. 
 - Connecticut Physicians [were surveyed](https://europepmc.org/abstract/med/10186700).
 - Maryland Physicians [were surveyed](https://doi.org/10.1093/infdis/173.5.1260)
 -  Medical records in Wisconsin [were reviewd](https://academic.oup.com/aje/article/155/12/1120/123221)
 
*Maine Estimates of errors*

[There are 2011-2016 estimates of prevelance](https://data.mainepublichealth.gov/tracking/metadata-lyme-prevalence) by town in Maine. Because Prevelance = Incidence x Average duration of disease, we may be able to compare our estimates to prevelance data as measured by the survey. However, prevelance is estimated by the question "Have you ever been told by a doctor, nurse, or other health professional that you have Lyme disease?”. This question does not capture populations that would not have intereacted with medical profesionals. However, it could be a cool benchmark on the state/ on the error assosiated with individuals who do intereact with medical profesionals, but who's disease does not meet the criteria of either probable or confirmed. 

 
